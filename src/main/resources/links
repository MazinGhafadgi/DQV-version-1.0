-- Data Science over the Movies Dataset with Spark, Scala and some SQL. And some Python.(Part 1) --
https://towardsdatascience.com/data-science-over-the-movies-dataset-with-spark-scala-and-some-sql-and-some-python-part-1-f5fd4ee8509e

-- Reconciliation --
https://medium.com/analytics-vidhya/data-reconciliation-in-spark-b185c6a2952b

--- Good source of creating dataframes ----
https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-datasets.html

-- filtering and partition
https://mungingdata.com/apache-spark/filter-where/


-- good source for implicitly and implict in scala
https://stackoverflow.com/questions/26143980/assign-an-operator-to-a-variable-in-scala


-- bigquery-connector
https://github.com/GoogleCloudDataproc/spark-bigquery-connector

-- visualize-data-studio
https://cloud.google.com/bigquery/docs/visualize-data-studio

-- Scala collect
https://medium.com/@sergigp/using-scala-collect-3a9880f71e23

-- CountMinSketchOnSpark
https://github.com/viirya/CountMinSketchOnSpark

-- data-profiling-best-practices
-- https://panoply.io/analytics-stack-guide/data-profiling-best-practices/

-- json schema
https://json-schema.org/understanding-json-schema/reference/conditionals.html


-- how to add two columns
df = df.withColumn('result', sum(df[col] for col in df.columns))
https://stackoverflow.com/questions/53297872/how-can-i-sum-multiple-columns-in-a-spark-dataframe-in-pyspark

--
https://docs.oracle.com/en-us/iaas/data-safe/doc/sensitive-types.html

